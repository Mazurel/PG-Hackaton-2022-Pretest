{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import re\n",
    "import random\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = io.open(\"../dataset/curses_55k.txt\", mode=\"r\", encoding=\"utf-8\")\n",
    "data = f.read()\n",
    "data = data.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strips whitespaces from data\n",
    "#data = [x.strip(' ') for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gówn0',\n",
       " 'afa',\n",
       " 'bladź',\n",
       " 'bl0łdżob',\n",
       " 'brandzl0wać',\n",
       " 'brandzl0wanie',\n",
       " 'burdelchata',\n",
       " 'burdelówa',\n",
       " 'bzykać',\n",
       " 'bzykank0']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hash table with single letters as hashes\n",
    "profanity_hash = {}\n",
    "for word in data[:-1]:\n",
    "    key = word[0]\n",
    "    if key in profanity_hash.keys():\n",
    "        profanity_hash[key].append(word)\n",
    "    else:\n",
    "        profanity_hash[key]=[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def censor(sentence = \"\"):\n",
    "    new_sentence = \"\"\n",
    "    \n",
    "    for word in sentence.split():\n",
    "        if word[0] in profanity_hash.keys():\n",
    "            if word in profanity_hash[word[0]]:\n",
    "                new_sentence += '*'*len(word) + ' '\n",
    "            else:\n",
    "                new_sentence += word + ' '\n",
    "        else:\n",
    "            new_sentence += word + ' '    \n",
    "            \n",
    "    return new_sentence[:-1] # [:-1] deletes space at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ja ******** co za **** debil i to pisał a a a.'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "censor(\"Ja pierdolę co za chuj debil i to pisał a a a.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_variances_alg(word):\n",
    "    \n",
    "    # changing polish chars\n",
    "    word = word.replace('ą','a').replace('ę', 'e').replace('ź','z').replace('ż', 'z').replace('ó','o').replace('ł', 'l').replace('ć','c').replace('ń','n').replace('ś','s')\n",
    "    \n",
    "    dictionary_no_big_letters = {'o':'0','b':'8','s':'5','e':'3','g':'9','z':'2','a':'4','u':'v','w':'vv','l':'I','I':'l'}\n",
    "    dictionary = {'o':'0','O':'0','b':'8','B':'8','s':'5','S':'5','e':'3','E':'3','G':'6','g':'9','z':'2','Z':'2','a':'@','A':'4','T':'7','u':'v','w':'vv','l':'I','I':'l'}\n",
    "\n",
    "    list_keys = list(dictionary_no_big_letters.keys())\n",
    "    list_values = list(dictionary_no_big_letters.values())\n",
    "    word_variances = []\n",
    "    lista = []\n",
    "    output= []\n",
    "    length = 20\n",
    "    for i in range(length):\n",
    "        lista.append(word)\n",
    "    for key,value in dictionary_no_big_letters.items(): #loop which creating words with changed letters one by one from the first letter to the last letter\n",
    "        for j in range(0,10):\n",
    "             for i in range(0,length):\n",
    "                    output = re.sub(key, value, lista[i], j)\n",
    "                    word_variances.append(output)\n",
    "    for key,value in dictionary_no_big_letters.items(): #loop which creating  words with changed letters one by one from the last letter to the first letter\n",
    "        for j in range(0,10):\n",
    "             for i in range(0,length):\n",
    "                    regex = key + \"(?!.*\" + key + \")\" \n",
    "                    output2 = re.sub(regex, value, lista[i], j)\n",
    "                    word_variances.append(output2)\n",
    "                       \n",
    "    full_list = []\n",
    "    mapIndexPosition = list(zip(list_keys, list_values))\n",
    "    random.shuffle(mapIndexPosition)\n",
    "    list_keys_1,list_values_1 = zip(*mapIndexPosition) #shuffeling of lists of keys and values(with no missing indexes) to make combination of two letters \n",
    "    \n",
    "    mapIndexPosition2 = list(zip(list_keys, list_values))\n",
    "    random.shuffle(mapIndexPosition2)\n",
    "    list_keys_2,list_values_2 = zip(*mapIndexPosition2)\n",
    "\n",
    "    for elem in range(len(list_keys)):\n",
    "        list_out = [element.replace(list_keys[elem],list_values[elem]).replace(list_keys_1[elem],list_values_1[elem]).replace(list_keys_2[elem],list_values_2[elem]) for element in lista]\n",
    "        full_list += list_out\n",
    "    \n",
    "    word_variances = word_variances + full_list #filling a list with variances\n",
    "\n",
    "    for elem in range(len(list_keys_1)):\n",
    "        list_out = [element.replace(list_keys_1[elem],list_values_1[elem]).replace(list_keys_2[elem],list_values_2[elem]) for element in lista]\n",
    "        full_list += list_out\n",
    "    \n",
    "    word_variances = word_variances + full_list\n",
    "    \n",
    "    mapIndexPosition = list(zip(list_keys, list_values))\n",
    "    random.shuffle(mapIndexPosition)\n",
    "    list_keys_1,list_values_1 = zip(*mapIndexPosition)\n",
    "    \n",
    "    mapIndexPosition2 = list(zip(list_keys, list_values))\n",
    "    random.shuffle(mapIndexPosition2)\n",
    "    list_keys_2,list_values_2 = zip(*mapIndexPosition2)\n",
    "\n",
    "    for elem in range(len(list_keys_1)):\n",
    "        list_out = [element.replace(list_keys_1[elem],list_values_1[elem]).replace(list_keys_2[elem],list_values_2[elem]) for element in lista]\n",
    "        full_list += list_out\n",
    "    \n",
    "    word_variances = word_variances + full_list\n",
    "    \n",
    "    for elem in range(len(list_keys)): # filling variances with \n",
    "        list_out = [element.replace(list_keys[0],list_values[0]).replace(list_keys[1],list_values[1]) for element in lista]\n",
    "        full_list += list_out\n",
    "    word_variances = word_variances + full_list\n",
    "    \n",
    "    for elem in range(len(list_keys)):\n",
    "        list_out = [element.replace(list_keys[0],list_values[0]).replace(list_keys[6],list_values[6]) for element in lista]\n",
    "        full_list += list_out\n",
    "    word_variances = word_variances + full_list\n",
    "    \n",
    "    for elem in range(len(list_keys)):\n",
    "        list_out = [element.replace(list_keys[3],list_values[3]).replace(list_keys[6],list_values[6]) for element in lista]\n",
    "        full_list += list_out\n",
    "    word_variances = word_variances + full_list\n",
    "    \n",
    "    for elem in range(len(list_keys)):\n",
    "        list_out = [element.replace(list_keys[3],list_values[3]).replace(list_keys[6],list_values[6]).replace(list_keys[0],list_values[0]) for element in lista]\n",
    "        full_list += list_out\n",
    "    word_variances = word_variances + full_list\n",
    "    \n",
    "    for i in range(len(word)): #loop which generates words with space gaps every letter\n",
    "        full_list.append(word[0:i]+\" \"+word[i:len(word)])\n",
    "    word_variances = word_variances + full_list    \n",
    "    for i in range(len(word)): #loop which generates words with double letter\n",
    "        full_list.append(word[0:i]+word[i-1]+word[i:len(word)])\n",
    "    word_variances = word_variances + full_list\n",
    "\n",
    "    return list(set(word_variances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_words(word: str, profanity_hash: dict) -> dict:\n",
    "    word = word.lower()\n",
    "    similar_words = word_variances_alg(word)\n",
    "    print(f\"similiar: {similar_words}\")\n",
    "    for word in similar_words:\n",
    "        key = word[0]\n",
    "        print(f\"word={word}, key={key}\")\n",
    "        if key in profanity_hash.keys():\n",
    "            if word not in profanity_hash[key]:\n",
    "                print(f\"dodaj {word}\")\n",
    "                profanity_hash[key].append(word)\n",
    "        else:\n",
    "            profanity_hash[key] = [word]\n",
    "\n",
    "    return profanity_hash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "similiar: ['jebac', 'jebaac', 'jjebac', 'jeba c', 'j3b4c', 'jeb ac', 'jeb4c', ' jebac', 'jeebac', 'je bac', 'j ebac', 'j3bac', 'je8ac', 'je84c', 'cjebac', 'jebbac', 'j38ac']\n",
      "word=jebac, key=j\n",
      "dodaj jebac\n",
      "word=jebaac, key=j\n",
      "dodaj jebaac\n",
      "word=jjebac, key=j\n",
      "dodaj jjebac\n",
      "word=jeba c, key=j\n",
      "dodaj jeba c\n",
      "word=j3b4c, key=j\n",
      "dodaj j3b4c\n",
      "word=jeb ac, key=j\n",
      "dodaj jeb ac\n",
      "word=jeb4c, key=j\n",
      "dodaj jeb4c\n",
      "word= jebac, key= \n",
      "word=jeebac, key=j\n",
      "dodaj jeebac\n",
      "word=je bac, key=j\n",
      "dodaj je bac\n",
      "word=j ebac, key=j\n",
      "dodaj j ebac\n",
      "word=j3bac, key=j\n",
      "dodaj j3bac\n",
      "word=je8ac, key=j\n",
      "dodaj je8ac\n",
      "word=je84c, key=j\n",
      "dodaj je84c\n",
      "word=cjebac, key=c\n",
      "dodaj cjebac\n",
      "word=jebbac, key=j\n",
      "dodaj jebbac\n",
      "word=j38ac, key=j\n",
      "dodaj j38ac\n"
     ]
    }
   ],
   "source": [
    "changed_table = add_words(\"Jebać\", profanity_hash)\n",
    "# changed_table[\"c\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
